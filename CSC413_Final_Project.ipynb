{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NUvNx1_fM2Sv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import transformers\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import re\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive\n",
        "import os, glob\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import re\n",
        "from pathlib import PurePosixPath\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA LOADING AND PREPROCESSING"
      ],
      "metadata": {
        "id": "fi-qoELX_YoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Adjust these paths to match your folder structure\n",
        "DATA_ARCHIVE_DIR = \"/content/drive/MyDrive/csc413-chexpert\"  # shared folder\n",
        "DATA_LABELS_DIR = \"/content/drive/MyDrive/train+valid\"\n",
        "LOCAL_DATA_ROOT  = \"/content/chexpert_data\"                  # local SSD on VM\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "MJCQ4is4_Zk8",
        "outputId": "1680bd60-0e88-49e8-9d31-68d5cccb7881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-375253555.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Adjust these paths to match your folder structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDATA_ARCHIVE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/csc413-chexpert\"\u001b[0m  \u001b[0;31m# shared folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mDATA_LABELS_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/train+valid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If `chexpert_data` is courupted use the following code to delete it:"
      ],
      "metadata": {
        "id": "tjn5peUj_kiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOCAL_DATA_ROOT = \"/content/chexpert_data\"\n",
        "\n",
        "# # Delete any partial extraction\n",
        "# !rm -rf \"{LOCAL_DATA_ROOT}\"\n",
        "\n",
        "# import os\n",
        "# os.makedirs(LOCAL_DATA_ROOT, exist_ok=True)"
      ],
      "metadata": {
        "id": "nYjvt5kW_Z0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -y install unrar > /dev/null\n",
        "\n",
        "rar_files = sorted(glob.glob(os.path.join(DATA_ARCHIVE_DIR, \"*.rar\")))\n",
        "print(f\"Found {len(rar_files)} RAR files in shared folder\")\n",
        "\n",
        "for r in tqdm(rar_files, desc=\"Extracting RAR archives\"):\n",
        "    !unrar x -y -idq \"{r}\" \"{LOCAL_DATA_ROOT}/\" > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "hT8A7zk3_Z12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rsync -a --info=progress2 \"{DATA_LABELS_DIR}/\" \"{LOCAL_DATA_ROOT}/\""
      ],
      "metadata": {
        "id": "DmLGD9K0s349"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOCAL_DATA_ROOT = \"/content/chexpert_data\"  # where you unrar’d\n",
        "\n",
        "# quick sanity check\n",
        "dirs = !find \"{LOCAL_DATA_ROOT}\" -maxdepth 2 -type d | head -n 20\n",
        "dirs\n"
      ],
      "metadata": {
        "id": "cFstAYz5_Z37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all JPG/PNG images under LOCAL_DATA_ROOT\n",
        "image_paths = []\n",
        "for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
        "    image_paths.extend(\n",
        "        glob.glob(os.path.join(LOCAL_DATA_ROOT, \"**\", ext), recursive=True)\n",
        "    )\n",
        "\n",
        "print(\"Total images:\", len(image_paths))\n",
        "\n",
        "def parse_path(p):\n",
        "    p = Path(p)\n",
        "    # .../CheXpert-v1.0-train1-512px-letterboxed/patientXXXX/studyY/view1_frontal.jpg\n",
        "    patient_id = p.parents[2].name   # 'patient00001'\n",
        "    study_id   = p.parents[1].name   # 'study1'\n",
        "    view_name  = p.stem              # 'view1_frontal'\n",
        "    return patient_id, study_id, view_name\n",
        "\n",
        "records = []\n",
        "for path in image_paths:\n",
        "    patient_id, study_id, view_name = parse_path(path)\n",
        "    records.append(\n",
        "        {\n",
        "            \"image_path\": path,\n",
        "            \"patient_id\": patient_id,\n",
        "            \"study_id\": study_id,\n",
        "            \"view\": view_name,\n",
        "        }\n",
        "    )\n",
        "\n",
        "df = pd.DataFrame.from_records(records)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "wHzQyV0l_sSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: these files need to be added manually for now, but we will automate soon\n",
        "# point these at wherever the CSVs are in your extracted folder\n",
        "TRAIN_CSV = os.path.join(LOCAL_DATA_ROOT, \"train.csv\")\n",
        "VALID_CSV = os.path.join(LOCAL_DATA_ROOT, \"valid.csv\")\n",
        "\n",
        "train_labels = pd.read_csv(TRAIN_CSV)\n",
        "valid_labels = pd.read_csv(VALID_CSV)\n",
        "\n",
        "def parse_label_path(s):\n",
        "    p = PurePosixPath(str(s).replace(\"\\\\\", \"/\"))\n",
        "    return p.parts[-3], p.parts[-2], p.stem  # patientXXXX, studyY, view stem\n",
        "\n",
        "for lab_df in (train_labels, valid_labels):\n",
        "    parsed = lab_df[\"Path\"].apply(parse_label_path)\n",
        "    lab_df[\"patient_id\"] = parsed.apply(lambda t: t[0])\n",
        "    lab_df[\"study_id\"]   = parsed.apply(lambda t: t[1])\n",
        "    lab_df[\"view\"]       = parsed.apply(lambda t: t[2])\n",
        "\n",
        "pat_re  = re.compile(r\"patient\\d+$\")\n",
        "study_re = re.compile(r\"study\\d+$\")\n",
        "\n",
        "def parse_from_image_path(path_str: str):\n",
        "    parts = PurePosixPath(str(path_str).replace(\"\\\\\", \"/\")).parts\n",
        "\n",
        "    # find .../patientXXXX/studyY/<file>\n",
        "    for i in range(len(parts) - 2):\n",
        "        if pat_re.fullmatch(parts[i]) and study_re.fullmatch(parts[i+1]):\n",
        "            patient_id = parts[i]\n",
        "            study_id   = parts[i+1]\n",
        "            view       = PurePosixPath(parts[i+2]).stem\n",
        "            return patient_id, study_id, view\n",
        "\n",
        "    # fallback (rare)\n",
        "    return parts[-3], parts[-2], PurePosixPath(parts[-1]).stem\n",
        "\n",
        "parsed = df[\"image_path\"].apply(parse_from_image_path)\n",
        "df[\"patient_id\"] = parsed.apply(lambda t: t[0])\n",
        "df[\"study_id\"]   = parsed.apply(lambda t: t[1])\n",
        "df[\"view\"]       = parsed.apply(lambda t: t[2])"
      ],
      "metadata": {
        "id": "7ZxGmG3S_sUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_COLS = [\n",
        "    \"No Finding\", \"Enlarged Cardiomediastinum\", \"Cardiomegaly\", \"Lung Opacity\",\n",
        "    \"Lung Lesion\", \"Edema\", \"Consolidation\", \"Pneumonia\", \"Atelectasis\",\n",
        "    \"Pneumothorax\", \"Pleural Effusion\", \"Pleural Other\", \"Fracture\",\n",
        "    \"Support Devices\"\n",
        "]\n",
        "\n",
        "train_tab = df.merge(train_labels[[\"patient_id\",\"study_id\",\"view\"] + LABEL_COLS],\n",
        "                     on=[\"patient_id\",\"study_id\",\"view\"], how=\"inner\")\n",
        "\n",
        "valid_tab = df.merge(valid_labels[[\"patient_id\",\"study_id\",\"view\"] + LABEL_COLS],\n",
        "                     on=[\"patient_id\",\"study_id\",\"view\"], how=\"inner\")\n",
        "\n",
        "def y_dx_to_prompts(y_dx):\n",
        "    # y_dx: (B,14) tensor with tokens {0 blank, 1 neg, 2 pos, 3 uncertain}\n",
        "    prompts = []\n",
        "    for row in y_dx.detach().cpu().tolist():\n",
        "        parts = []\n",
        "        for name, tok in zip(LABEL_COLS, row):\n",
        "            if tok == 0:\n",
        "                continue\n",
        "            elif tok == 1:\n",
        "                parts.append(f\"{name}: negative\")\n",
        "            elif tok == 2:\n",
        "                parts.append(f\"{name}: positive\")\n",
        "            elif tok == 3:\n",
        "                parts.append(f\"{name}: uncertain\")\n",
        "        prompts.append(\", \".join(parts) if parts else \"No Finding\")\n",
        "    return prompts"
      ],
      "metadata": {
        "id": "h97zvqkc_sWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splint into train, validate and test sets:"
      ],
      "metadata": {
        "id": "k47uSkas_w58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use provided valid.csv as TEST\n",
        "test_split = valid_tab.reset_index(drop=True)\n",
        "\n",
        "# Create our own VAL split from the training table (patient-level split)\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.10, random_state=42)\n",
        "train_idx, val_idx = next(gss.split(train_tab, groups=train_tab[\"patient_id\"]))\n",
        "\n",
        "train_split = train_tab.iloc[train_idx].reset_index(drop=True)\n",
        "val_split   = train_tab.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "gss_small = GroupShuffleSplit(n_splits=1, test_size=0.99, random_state=123)\n",
        "small_idx, _ = next(gss_small.split(train_split, groups=train_split[\"patient_id\"]))\n",
        "train_split_small = train_split.iloc[small_idx].reset_index(drop=True)\n",
        "\n",
        "print(\"small train:\", len(train_split_small), \"of\", len(train_split))\n",
        "print(\"train/val/test:\", len(train_split), len(val_split), len(test_split))\n",
        "print(\"unique patients:\", train_split[\"patient_id\"].nunique(),\n",
        "      val_split[\"patient_id\"].nunique(),\n",
        "      test_split[\"patient_id\"].nunique())"
      ],
      "metadata": {
        "id": "UZ8bMhik_xBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function maps CheXpert label to an integer code:\n",
        "\n",
        "NaN -> 0 = “blank” / not mentioned in report\n",
        "\n",
        "0 -> 1 = negative\n",
        "\n",
        "1 -> 2 = positive\n",
        "\n",
        "2 -> 3 = uncertain\n"
      ],
      "metadata": {
        "id": "6pqZr-_q_4Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_label(v):\n",
        "    if pd.isna(v): return 0\n",
        "    if v == 0.0:     return 1\n",
        "    if v == 1.0:     return 2\n",
        "    if v == -1.0:    return 3\n",
        "    return 0\n",
        "\n",
        "for c in LABEL_COLS:\n",
        "    train_split[c] = train_split[c].map(encode_label)\n",
        "    val_split[c]   = val_split[c].map(encode_label)\n",
        "    test_split[c]  = test_split[c].map(encode_label)\n",
        "    train_split_small[c] = train_split_small[c].map(encode_label)"
      ],
      "metadata": {
        "id": "dww8IM3v_xDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tf = transforms.Compose([\n",
        "    transforms.Lambda(lambda im: im.convert(\"L\").convert(\"RGB\")),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "])\n",
        "\n",
        "eval_tf = transforms.Compose([\n",
        "    transforms.Lambda(lambda im: im.convert(\"L\").convert(\"RGB\")),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "])"
      ],
      "metadata": {
        "id": "N0B_bgly_xFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CheXpertDataset(Dataset):\n",
        "    def __init__(self, tab, label_cols, transform):\n",
        "        self.tab = tab.reset_index(drop=True)\n",
        "        self.label_cols = label_cols\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.tab)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.tab.iloc[idx]\n",
        "        img = Image.open(row[\"image_path\"])\n",
        "        img = self.transform(img)\n",
        "        y = self.tab[self.label_cols].iloc[idx].to_numpy(dtype=\"int64\", copy=False)\n",
        "        y_dx = torch.from_numpy(y)\n",
        "        prompt = y_dx_to_prompts(torch.from_numpy(y[None, :]))[0]\n",
        "        return {\"pixel_values\": img, \"y_dx\": y_dx, \"prompts\": prompt, \"path\": row[\"image_path\"]}\n",
        "\n",
        "train_ds = CheXpertDataset(train_split, LABEL_COLS, train_tf)\n",
        "val_ds   = CheXpertDataset(val_split,   LABEL_COLS, eval_tf)\n",
        "test_ds  = CheXpertDataset(test_split,  LABEL_COLS, eval_tf)\n",
        "train_ds_small = CheXpertDataset(train_split_small, LABEL_COLS, train_tf)\n",
        "\n",
        "train_loader_small = DataLoader(train_ds_small, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=8, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "mbz0wc30_6yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) one-batch sanity check\n",
        "b = next(iter(train_loader))\n",
        "print(\"pixel:\", b[\"pixel_values\"].shape, b[\"pixel_values\"].dtype,\n",
        "      float(b[\"pixel_values\"].min()), float(b[\"pixel_values\"].max()))\n",
        "print(\"labels:\", b[\"y_dx\"].shape, b[\"y_dx\"].dtype, torch.unique(b[\"y_dx\"]))\n",
        "print(np.unique(train_split[LABEL_COLS].to_numpy()))"
      ],
      "metadata": {
        "id": "zg9LDPya_600"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOADING THE MODEL AND ADDING LORA\n"
      ],
      "metadata": {
        "id": "vPcjvq1o_bWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"sd-legacy/stable-diffusion-v1-5\"\n",
        "# For GPU use, pipe = pipe.to('cuda')\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "\n",
        "transformer_weights_str_pattern_lora = re.compile(r\"(attn1|attn2)\\.(to_q|to_k|to_v|to_out\\.0)\\.(weight|bias)$\")"
      ],
      "metadata": {
        "id": "0UsudqYGBH-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access U-Net Parameters\n",
        "count = 0\n",
        "for name, param in pipe.unet.named_parameters():\n",
        "    param.requires_grad = False # freezes layer\n",
        "    if transformer_weights_str_pattern_lora.search(name):\n",
        "        #print(name, param.shape)\n",
        "        count += param.numel()\n",
        "\n",
        "# 160 layers 93536640 trainable parameters.\n",
        "print(\"Number of LoRA trainable parameters: {}\".format(count))"
      ],
      "metadata": {
        "id": "eXRhrw5dBINk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access Variational Autoencder (VAE) params\n",
        "for name, param in pipe.vae.named_parameters():\n",
        "    param.requires_grad = False # freeze layers\n",
        "\n",
        "# Access Text Encoder params\n",
        "for name, param in pipe.text_encoder.named_parameters():\n",
        "    param.requires_grad = False # freeze layers"
      ],
      "metadata": {
        "id": "9MyZwWu_BfYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA config\n",
        "lora_config = LoraConfig(\n",
        "    r=1, # Low-rank dimension\n",
        "    lora_alpha=16, # Scaling\n",
        "    target_modules=['to_q', 'to_k', 'to_v', 'to_out.0'],\n",
        "    lora_dropout=0.05,\n",
        "    bias='none'\n",
        ")\n",
        "\n",
        "# Apply LoRA to U-Net\n",
        "pipe.unet = get_peft_model(pipe.unet, lora_config)"
      ],
      "metadata": {
        "id": "q8PfAwl-BffI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_params = 0\n",
        "for name, param in pipe.unet.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        #print(name, param.shape)\n",
        "        finetune_params += param.numel()\n",
        "\n",
        "# 797184 instead of 860M parameters\n",
        "print(f\"Total trainable parameters: {finetune_params}\")"
      ],
      "metadata": {
        "id": "ovFOxmT_BfjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GENERATING FAKE DATA TO TEST\n"
      ],
      "metadata": {
        "id": "A-ztQ1mNhaI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define synthetic dataset ---\n",
        "# class SyntheticDataset(Dataset):\n",
        "#     def __init__(self, num_samples=10, image_size=(3, 64, 64)):\n",
        "#         self.num_samples = num_samples\n",
        "#         self.image_size = image_size\n",
        "#         # Generate random \"prompts\" as short strings\n",
        "#         self.prompts = [f\"A synthetic image {i}\" for i in range(num_samples)]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.num_samples\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         # Random image in [-1, 1] like SD expects\n",
        "#         image = torch.randn(*self.image_size)\n",
        "#         prompt = self.prompts[idx]\n",
        "#         return image, prompt\n",
        "\n",
        "# # --- 2. Create DataLoader ---\n",
        "# dataset = SyntheticDataset(num_samples=5, image_size=(3, 64, 64))\n",
        "# dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "oQ6C5GZOgRyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INITIAL TEST GENERATING AN IMAGE"
      ],
      "metadata": {
        "id": "Bk9aYEJb-PLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# INITIAL TEST GENERATING AN IMAGE\n",
        "\n",
        "# 4. Define a test prompt based on your fine-tuning data/style\n",
        "test_prompt = \"A high resolution XRay with the following - Lung Opacity: positive, Edema: positive, Pneumonia: uncertain, Support Devices: positive\"\n",
        "\n",
        "# 5. Run inference to generate the test image\n",
        "pipe_test = pipe.to(\"cuda\")\n",
        "generator = torch.Generator(\"cuda\").manual_seed(42)\n",
        "test_image = pipe_test(\n",
        "    test_prompt,\n",
        "    num_inference_steps=30,\n",
        "    guidance_scale=7.5,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "\n",
        "# 6. Display the image\n",
        "display(test_image) # Requires running in a Colab/Jupyter notebook environment"
      ],
      "metadata": {
        "id": "cAWWAOXg-ORY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING LOOP"
      ],
      "metadata": {
        "id": "O5aCYet8hNy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Separate Components from Pipeline\n",
        "device = torch.device(\"cuda\")\n",
        "vae = pipe.vae.to(device)\n",
        "unet = pipe.unet.to(device)\n",
        "text_encoder = pipe.text_encoder.to(device) # change from float to half precision for GPU\n",
        "tokenizer = pipe.tokenizer\n",
        "noise_scheduler = pipe.scheduler"
      ],
      "metadata": {
        "id": "X5DoGW17hKtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freese the VAE and text encoder, but leave the unet for training\n",
        "\n",
        "# change to train_loader for full set, train_loader_small is 1% of train data\n",
        "TRAINING_SET = train_loader_small\n",
        "\n",
        "vae.requires_grad_(False)\n",
        "text_encoder.requires_grad_(False)\n",
        "unet.train()\n",
        "\n",
        "optimizer = torch.optim.AdamW(unet.parameters(), lr=1e-5)\n",
        "\n",
        "pbar = tqdm(TRAINING_SET, desc=\"Train\", total=len(TRAINING_SET))\n",
        "\n",
        "for step, batch in enumerate(pbar):\n",
        "    # Clear CUDA cache at the start of each iteration to free up any unallocated memory\n",
        "    # Primary fix is to reduce batch_size in DataLoader (e.g., in cell mbz0wc30_6yv)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    images = batch[\"pixel_values\"].to(device=device, dtype=vae.dtype)\n",
        "    y_dx   = batch[\"y_dx\"].to(device)\n",
        "    prompts = batch[\"prompts\"]\n",
        "\n",
        "    # 1. latents\n",
        "    latents = vae.encode(images).latent_dist.sample()\n",
        "    latents = latents * 0.18215\n",
        "\n",
        "    # 2. timesteps\n",
        "    t = torch.randint(0, noise_scheduler.num_train_timesteps, (latents.size(0),), device=latents.device, dtype=torch.long)\n",
        "\n",
        "    # 3. noise + noisy latents\n",
        "    noise = torch.randn_like(latents)\n",
        "    noisy_latents = noise_scheduler.add_noise(latents, noise, t)\n",
        "\n",
        "    # 4. text embeddings\n",
        "    input_ids = tokenizer(prompts, padding=\"max_length\", truncation=True, max_length=tokenizer.model_max_length, return_tensors=\"pt\").input_ids\n",
        "    input_ids = input_ids.to(device)\n",
        "    text_embeds = text_encoder(input_ids)[0]\n",
        "\n",
        "    # 5. UNet predicts noise\n",
        "    noise_pred = unet(noisy_latents, t, encoder_hidden_states=text_embeds).sample\n",
        "\n",
        "    # 6. loss\n",
        "    loss = F.mse_loss(noise_pred, noise)\n",
        "\n",
        "    # 7. optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    pbar.set_postfix(loss=float(loss.item()))"
      ],
      "metadata": {
        "id": "g_zP0cqHcR-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAKE SURE TO CHANGE THE FOLDER NAME BEFORE EACH RUN!!!!!\n",
        "\n",
        "# Create the path string\n",
        "output_dir = \"/content/drive/MyDrive/lora_weights/my_project_v1\"\n",
        "\n",
        "# Create the folder (if it doesn't exist)\n",
        "import os\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save the weights\n",
        "pipe.unet.save_pretrained(output_dir, safe_serialization=True)\n",
        "print(f\"LoRA weights successfully saved to: {output_dir}\")"
      ],
      "metadata": {
        "id": "mxAbweMOo3Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINAL TEST GENERATING AN IMAGE\n"
      ],
      "metadata": {
        "id": "t8pmZWcVbn1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the weights back to the unet from saved\n",
        "\n",
        "from peft import PeftModel\n",
        "\n",
        "\n",
        "weights_dir = \"/content/drive/MyDrive/lora_weights/my_project_v1\"\n",
        "\n",
        "pipe.unet = PeftModel.from_pretrained(\n",
        "    pipe.unet,          # The base model component to attach to\n",
        "    weights_dir,          # The path to your saved LoRA weights\n",
        "    is_trainable=False  # Set to False for inference\n",
        ")\n",
        "\n",
        "print(f\"LoRA weights loaded onto pipe.unet using PeftModel.\")"
      ],
      "metadata": {
        "id": "ANM4ZroSaYyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST GENERATING AN IMAGE\n",
        "\n",
        "# 4. Define a test prompt based on your fine-tuning data/style\n",
        "test_prompt = \"A high resolution XRay with the following - Lung Opacity: positive, Edema: positive, Pneumonia: uncertain, Support Devices: positive\"\n",
        "\n",
        "# 5. Run inference to generate the test image\n",
        "pipe = pipe.to(\"cuda\")\n",
        "generator = torch.Generator(\"cuda\").manual_seed(42)\n",
        "test_image = pipe(\n",
        "    test_prompt,\n",
        "    num_inference_steps=30,\n",
        "    guidance_scale=7.5,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "\n",
        "# 6. Display the image\n",
        "display(test_image) # Requires running in a Colab/Jupyter notebook environment"
      ],
      "metadata": {
        "id": "9MFrysqeanMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipe.unet = unet --> update pipe"
      ],
      "metadata": {
        "id": "FMlgEbHLh47J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}